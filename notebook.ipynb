{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "15QG5zOHhihX",
        "outputId": "636e15d0-3d04-4883-daaf-bc59960db04b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n"
          ]
        }
      ],
      "source": [
        "# Installation de XGBoost (souvent d√©j√† install√© dans Colab, mais c'est une bonne pratique)\n",
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tX3_KcYjpTS6",
        "outputId": "762bfc0c-1c9a-40fc-fa8d-0421f8dbf74e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Biblioth√®ques import√©es avec succ√®s.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
        "\n",
        "print(\"Biblioth√®ques import√©es avec succ√®s.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPg1hMd-p2ES"
      },
      "source": [
        "√âtape 1 : Chargement des Donn√©es et Inspection Rapide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TkWSAwoIp4Nm",
        "outputId": "4425aaf5-aca4-4d44-b069-11f50afe44c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- TRAIN SET ---\n",
            "                         transaction_id  step      type  amount customer_id  \\\n",
            "0  38d8cd1a-ab64-48a8-982b-547db096f8a5   421   PAYMENT  311000   C13646530   \n",
            "1  2440928e-8a4c-4e74-a9c5-6329668be13d   325   PAYMENT  399600    C9452763   \n",
            "2  973c2a3c-5676-477c-ac30-81334b01e90d   565   PAYMENT    7500   C31260354   \n",
            "3  5413d0f4-b4f0-406f-bd91-91de1dce573c   511  TRANSFER   94000    C8841991   \n",
            "4  c9fa99e2-42c8-4dd8-94ba-aa3e44bfdd98    63  CASH_OUT   15000    C3176716   \n",
            "\n",
            "   age  is_fraud  \n",
            "0   24         0  \n",
            "1   25         0  \n",
            "2   38         0  \n",
            "3   26         0  \n",
            "4   26         0  \n",
            "\n",
            "--- TEST SET ---\n",
            "                         transaction_id  step      type   amount customer_id  \\\n",
            "0  f9d47afa-6e9f-45a1-a443-afb5132e9986   494   PAYMENT   184500   C57389453   \n",
            "1  a3159433-df38-44d2-b6e1-3920b6f2a42f   322   PAYMENT   684000   C15998978   \n",
            "2  27b30f3c-7688-489f-9c77-d70981bf1a05   377  CASH_OUT  1344000   C48225516   \n",
            "3  c3566535-87b7-40d5-ac21-7874a193af11   592   PAYMENT    71100   C41411519   \n",
            "4  26ec3542-7f49-4252-b906-78157c647db8   450  CASH_OUT    13000   C37576173   \n",
            "\n",
            "   age  \n",
            "0   79  \n",
            "1   67  \n",
            "2   22  \n",
            "3   22  \n",
            "4   53  \n",
            "\n",
            "Taux de fraude dans le train set : 1.9833% (D√©s√©quilibre S√âV√àRE!)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    train_df = pd.read_csv(\"ressources/train.csv\")\n",
        "    test_df = pd.read_csv(\"ressources/test.csv\")\n",
        "\n",
        "    # Affichage des premi√®res lignes pour v√©rifier le chargement\n",
        "    print(\"--- TRAIN SET ---\")\n",
        "    print(train_df.head())\n",
        "    print(\"\\n--- TEST SET ---\")\n",
        "    print(test_df.head())\n",
        "\n",
        "    # V√©rification du d√©s√©quilibre (l'indice crucial de la d√©tection de fraude)\n",
        "    fraud_rate = train_df['is_fraud'].mean() * 100\n",
        "    print(f\"\\nTaux de fraude dans le train set : {fraud_rate:.4f}% (D√©s√©quilibre S√âV√àRE!)\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"ERREUR : Fichiers 'train.csv' ou 'test.csv' introuvables. V√©rifiez le nom et le chemin d'acc√®s.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs8Ph_reqH4b"
      },
      "source": [
        "√âtape 2 : Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoKXzs9iqSs-",
        "outputId": "3d11bdb3-6147-44d3-9441-c8618ed01af2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Feature Engineering termin√© et donn√©es s√©par√©es.\n"
          ]
        }
      ],
      "source": [
        "def create_temporal_features(df):\n",
        "    \"\"\"Cr√©ation des features temporelles (jour, heure, nuit, weekend) √† partir de 'step'.\"\"\"\n",
        "\n",
        "    # Le Step 1 est la premi√®re heure d'un LUNDI (jour 0)\n",
        "    df['day_of_week'] = ((df['step'] - 1) // 24) % 7 # 0=Lundi, 6=Dimanche\n",
        "    df['hour'] = (df['step'] - 1) % 24 # 0 √† 23\n",
        "\n",
        "    # 1 si la transaction a lieu la nuit (ex: 0h √† 6h)\n",
        "    df['is_night_time'] = ((df['hour'] >= 0) & (df['hour'] <= 6)).astype(int)\n",
        "    # 1 si la transaction a lieu le week-end (Samedi ou Dimanche)\n",
        "    df['is_weekend'] = ((df['day_of_week'] >= 5)).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "def advanced_feature_engineering(df):\n",
        "    \"\"\"Cr√©ation des features bas√©es sur le comportement du client (agr√©gations).\"\"\"\n",
        "\n",
        "    # Fr√©quence des transactions : Combien de fois le client a transig√© dans cette fen√™tre de 24h\n",
        "    df['step_24h_window'] = df['step'] // 24\n",
        "    df['client_txn_count_24h'] = df.groupby(['customer_id', 'step_24h_window'])['amount'].transform('count')\n",
        "\n",
        "    # Ratio d'anomalie : Montant de la transaction actuelle VS Montant moyen habituel pour ce type de transaction par ce client\n",
        "    mean_amount_by_client_type = df.groupby(['customer_id', 'type'])['amount'].transform('mean')\n",
        "    df['amount_vs_mean_type'] = df['amount'] / (mean_amount_by_client_type + 1e-6) # Ajout d'epsilon pour √©viter la division par z√©ro\n",
        "\n",
        "    # Indicateur pour les types √† haut risque\n",
        "    df['is_transfer_or_cashout'] = df['type'].apply(lambda x: 1 if x in ['TRANSFER', 'CASH_OUT'] else 0)\n",
        "\n",
        "    # Suppression de la colonne temporaire\n",
        "    df = df.drop('step_24h_window', axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Application des fonctions √† l'entra√Ænement et au test\n",
        "train_df = create_temporal_features(train_df.copy())\n",
        "train_df = advanced_feature_engineering(train_df)\n",
        "\n",
        "test_df_submission = test_df.copy() # Sauvegarde pour la soumission\n",
        "test_df = create_temporal_features(test_df.copy())\n",
        "test_df = advanced_feature_engineering(test_df)\n",
        "\n",
        "# S√©paration de la cible (y) et des features (X)\n",
        "X = train_df.drop(['is_fraud', 'transaction_id', 'customer_id', 'step'], axis=1)\n",
        "y = train_df['is_fraud']\n",
        "X_test_final = test_df.drop(['transaction_id', 'customer_id', 'step'], axis=1)\n",
        "\n",
        "# Division pour la validation (on garde 20% du train pour tester le mod√®le)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(\"‚úÖ Feature Engineering termin√© et donn√©es s√©par√©es.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe_wCq2JqzJV"
      },
      "source": [
        "√âtape 3 : Pr√©processeur et Baseline (R√©gression Logistique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9-DCmYQ1q_gz",
        "outputId": "3111e95e-665f-41e6-b972-89433d1cc9a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Entra√Ænement de la Baseline (R√©g. Logistique)...\n",
            "\n",
            "--- R√©sultats de la Baseline ---\n",
            "F1-Score Baseline: **0.1416**\n",
            "\n",
            "Matrice de Confusion (Baseline) :\n",
            " [[4569 1312]\n",
            " [  10  109]]\n",
            "\n",
            "Rapport de Classification (Baseline) :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.78      0.87      5881\n",
            "           1       0.08      0.92      0.14       119\n",
            "\n",
            "    accuracy                           0.78      6000\n",
            "   macro avg       0.54      0.85      0.51      6000\n",
            "weighted avg       0.98      0.78      0.86      6000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- D√©finition des Features pour le Pr√©processeur ---\n",
        "numerical_features = ['amount', 'age', 'client_txn_count_24h', 'amount_vs_mean_type']\n",
        "categorical_features = ['type', 'day_of_week', 'hour']\n",
        "boolean_features = ['is_night_time', 'is_weekend', 'is_transfer_or_cashout']\n",
        "\n",
        "# ColumnTransformer : Applique les bonnes transformations aux bonnes colonnes\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        # StandardScaler : Met les colonnes num√©riques √† la m√™me √©chelle (important pour la R√©g. Log.)\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        # OneHotEncoder : Convertit les variables cat√©gorielles (ex: 'type') en colonnes num√©riques (0 ou 1)\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "        ('bool', 'passthrough', boolean_features) # Laisse les 0/1 tranquilles\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# --- Pipeline de Baseline (R√©gression Logistique) ---\n",
        "log_reg_model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    # LogisticRegression avec class_weight='balanced' pour g√©rer le d√©s√©quilibre\n",
        "    ('classifier', LogisticRegression(random_state=42, class_weight='balanced', solver='liblinear', max_iter=1000))\n",
        "])\n",
        "\n",
        "# Entra√Ænement et √âvaluation de la Baseline\n",
        "print(\"üîÑ Entra√Ænement de la Baseline (R√©g. Logistique)...\")\n",
        "log_reg_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_baseline = log_reg_model.predict(X_val)\n",
        "\n",
        "print(\"\\n--- R√©sultats de la Baseline ---\")\n",
        "f1_baseline = f1_score(y_val, y_pred_baseline)\n",
        "print(f\"F1-Score Baseline: **{f1_baseline:.4f}**\")\n",
        "print(\"\\nMatrice de Confusion (Baseline) :\\n\", confusion_matrix(y_val, y_pred_baseline))\n",
        "print(\"\\nRapport de Classification (Baseline) :\\n\", classification_report(y_val, y_pred_baseline))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suiLv2jSrKNE"
      },
      "source": [
        "√âtape 4 : Mod√®le Avanc√© (XGBoost) et Optimisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TamlEeZHrN7A",
        "outputId": "d924310b-c839-489f-a16c-4426f25ba42c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîÑ Entra√Ænement du Mod√®le Final (XGBoost)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [06:21:59] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- R√©sultats du Mod√®le Final (XGBoost) ---\n",
            "F1-Score Final (XGBoost): **0.7117**\n",
            "\n",
            "Matrice de Confusion (XGBoost) :\n",
            " [[5819   62]\n",
            " [  19  100]]\n",
            "\n",
            "Rapport de Classification (XGBoost) :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99      5881\n",
            "           1       0.62      0.84      0.71       119\n",
            "\n",
            "    accuracy                           0.99      6000\n",
            "   macro avg       0.81      0.91      0.85      6000\n",
            "weighted avg       0.99      0.99      0.99      6000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- Calcul du poids pour la classe positive (Gestion du D√©s√©quilibre pour XGBoost) ---\n",
        "# On dit √† XGBoost que la classe '1' (fraude) est beaucoup plus importante\n",
        "scale_pos_weight_value = sum(y_train == 0) / sum(y_train == 1)\n",
        "\n",
        "# --- Pipeline XGBoost ---\n",
        "xgb_classifier = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    n_estimators=200, # Un peu plus d'arbres\n",
        "    learning_rate=0.08, # Un taux d'apprentissage mod√©r√©\n",
        "    scale_pos_weight=scale_pos_weight_value, # Appliquer le poids calcul√©\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "xgb_model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', xgb_classifier)\n",
        "])\n",
        "\n",
        "# Entra√Ænement du Mod√®le Final\n",
        "print(\"\\nüîÑ Entra√Ænement du Mod√®le Final (XGBoost)...\")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# √âvaluation du Mod√®le Final\n",
        "y_pred_xgb = xgb_model.predict(X_val)\n",
        "\n",
        "print(\"\\n--- R√©sultats du Mod√®le Final (XGBoost) ---\")\n",
        "f1_xgb = f1_score(y_val, y_pred_xgb)\n",
        "print(f\"F1-Score Final (XGBoost): **{f1_xgb:.4f}**\")\n",
        "print(\"\\nMatrice de Confusion (XGBoost) :\\n\", confusion_matrix(y_val, y_pred_xgb))\n",
        "print(\"\\nRapport de Classification (XGBoost) :\\n\", classification_report(y_val, y_pred_xgb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpPYDbOvrY22"
      },
      "source": [
        "√âtape 5 : G√©n√©ration de la Soumission Finale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1E3p68NErb7y",
        "outputId": "93e3a5d9-ede4-4779-aa61-90d1951fece4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîÑ Entra√Ænement final du XGBoost sur l'int√©gralit√© du TRAIN SET...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [06:22:55] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ G√©n√©ration des pr√©dictions pour la soumission...\n",
            "\n",
            "‚úÖ Fichier submission.csv g√©n√©r√© avec 10000 pr√©dictions. Vous pouvez le t√©l√©charger dans l'onglet 'Fichiers' de Colab.\n"
          ]
        }
      ],
      "source": [
        "# 1. Entra√Ænement final sur l'ensemble des donn√©es d'entra√Ænement (X complet, y complet)\n",
        "print(\"\\nüîÑ Entra√Ænement final du XGBoost sur l'int√©gralit√© du TRAIN SET...\")\n",
        "xgb_model.fit(X, y)\n",
        "\n",
        "# 2. Pr√©dictions sur le TEST SET\n",
        "print(\"üöÄ G√©n√©ration des pr√©dictions pour la soumission...\")\n",
        "test_predictions = xgb_model.predict(X_test_final)\n",
        "\n",
        "# 3. Cr√©ation du DataFrame de soumission\n",
        "submission = pd.DataFrame({\n",
        "    # On utilise les IDs originaux du test set\n",
        "    \"transaction_id\": test_df_submission[\"transaction_id\"],\n",
        "    # La pr√©diction est convertie en entier (0 ou 1)\n",
        "    \"is_fraud\": test_predictions.astype(int)\n",
        "})\n",
        "\n",
        "# 4. Sauvegarde du fichier submission.csv\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(f\"\\n‚úÖ Fichier submission.csv g√©n√©r√© avec {len(submission)} pr√©dictions. Vous pouvez le t√©l√©charger dans l'onglet 'Fichiers' de Colab.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
